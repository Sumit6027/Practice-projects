{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069c571e",
   "metadata": {},
   "source": [
    "## Red Wine Quality Prediction Project:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aaf6ef",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b387dba",
   "metadata": {},
   "source": [
    "Importing all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/DSData/master/winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf1a64",
   "metadata": {},
   "source": [
    "Instead of downloading the entire dataset on my local computer I am simply loading the file directly from the GitHub repository link using the raw option.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab156915",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df # Taking a look at the dataset's first and last 5 rows showcasing all the column names as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae1b47",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c315d5",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b0a26",
   "metadata": {},
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352eeff3",
   "metadata": {},
   "source": [
    "(1599, 12)\n",
    "I see that there are total 1599 rows and 12 columns present in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed59a6b",
   "metadata": {},
   "source": [
    "fixed acidity           0\n",
    "volatile acidity        0\n",
    "citric acid             0\n",
    "residual sugar          0\n",
    "chlorides               0\n",
    "free sulfur dioxide     0\n",
    "total sulfur dioxide    0\n",
    "density                 0\n",
    "pH                      0\n",
    "sulphates               0\n",
    "alcohol                 0\n",
    "quality                 0\n",
    "dtype: int64\n",
    "Luckily we do not see any missing values in any of the columns of our dataset so we don't have to worry about handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65ef42",
   "metadata": {},
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1599 entries, 0 to 1598\n",
    "Data columns (total 12 columns):\n",
    " #   Column                Non-Null Count  Dtype  \n",
    "---  ------                --------------  -----  \n",
    " 0   fixed acidity         1599 non-null   float64\n",
    " 1   volatile acidity      1599 non-null   float64\n",
    " 2   citric acid           1599 non-null   float64\n",
    " 3   residual sugar        1599 non-null   float64\n",
    " 4   chlorides             1599 non-null   float64\n",
    " 5   free sulfur dioxide   1599 non-null   float64\n",
    " 6   total sulfur dioxide  1599 non-null   float64\n",
    " 7   density               1599 non-null   float64\n",
    " 8   pH                    1599 non-null   float64\n",
    " 9   sulphates             1599 non-null   float64\n",
    " 10  alcohol               1599 non-null   float64\n",
    " 11  quality               1599 non-null   int64  \n",
    "dtypes: float64(11), int64(1)\n",
    "memory usage: 150.0 KB\n",
    "Great none of the columns have any object data type values and our label is the only integer value making all the feature columns as float datatype i.e. similar datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd28686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew() # acceptable range is +/-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa99903",
   "metadata": {},
   "source": [
    "fixed acidity           0.982751\n",
    "volatile acidity        0.671593\n",
    "citric acid             0.318337\n",
    "residual sugar          4.540655\n",
    "chlorides               5.680347\n",
    "free sulfur dioxide     1.250567\n",
    "total sulfur dioxide    1.515531\n",
    "density                 0.071288\n",
    "pH                      0.193683\n",
    "sulphates               2.428672\n",
    "alcohol                 0.860829\n",
    "quality                 0.217802\n",
    "dtype: float64\n",
    "Here we see the skewness information present in our dataset. We will ignore quality since it is our target label in the dataset. Now taking a look at all the feature columns we see that fixed acidity, volatile acidity, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, sulphates and alcohol are all outside the acceptable range of +/-0.5. This skewness indicates outliers being present in our dataset that will need to be treated if required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9a1ee",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d49c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(x ='quality', data = df)\n",
    "plt.xlabel('Quality of Red Wine')\n",
    "plt.ylabel('Count of Rows in the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857dcfc3",
   "metadata": {},
   "source": [
    "In the countplot representation we see the various categories of red wine quality and it shows that the number of data present for quality score 5 and 6 is way higher than it's counterparts. This indicates an imbalance which will need to be rectified so that our machine learning model do not get biased to a certain value during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "labels = df['quality']\n",
    "features = df.drop('quality', axis=1)\n",
    "\n",
    "for col in features.items():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(x=labels, y=col[index], data=df, color=\"deeppink\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b0faf",
   "metadata": {},
   "source": [
    "With the feature vs label barplot we are able to see the trend corresponding to the impact each has with respect to predicting the quality column (our target variable).\n",
    "\n",
    "Observations regarding feature compared to the label are: 01. fixed acidity vs quality - no fixed pattern 02. volatile acidity vs quality - there is a decreasing trend 03. citric acid vs quality - there is an increasing trend 04. residual sugar vs quality - no fixed pattern 05. chlorides vs quality - there is a decreasing trend 06. free sulfur dioxide vs quality - no fixed pattern as it is increasing then decreasing 07. total sulfur dioxide vs quality - no fixed pattern as it is increasing then decreasing 08. density vs quality - no pattern at all 09. pH vs quality - no pattern at all 10. sulphates vs quality - there is an increasing trend 11. alcohol vs quality - there is an increasing trend\n",
    "\n",
    "So here we can conclude that to get better quality wine citric acid, sulphates and alcohol columns play a major role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(15,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df.items():\n",
    "    sns.boxplot(y=col, data=df, ax=ax[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd4677",
   "metadata": {},
   "source": [
    "With the help of the above boxplot we are able to see the whisker details and outliers clearly. I am ignoring the continous outlier sections but the outliers that are single values and far away from the whiskers of the boxplot may need to be treated depending upon further analysis. Right now I am just trying to retain as much of data which is possible in the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(15,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df.items():\n",
    "    sns.distplot(value, ax=ax[index], hist=False, color=\"g\", kde_kws={\"shade\": True})\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b32c7",
   "metadata": {},
   "source": [
    "The distribution plots show that few of the columns are in normal distribution category showing a proper bell shape curve. However, we do see skewness in most of the feature columns like citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, sulphates and alcohol columns. We are going to ignore the label column since it is a categorical column and will need to fix the imbalance data inside it.\n",
    "\n",
    "With respect to the treatment of skewness and outliers I will perform the removal or treatment after I can see the accuracy dependency of the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bf3ce",
   "metadata": {},
   "source": [
    "## Correlation using a Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3101f",
   "metadata": {},
   "source": [
    " 1.Positive correlation - A correlation of +1 indicates a perfect positive correlation, meaning that both variables move in the same direction together.\n",
    "\n",
    "2.Negative correlation - A correlation of –1 indicates a perfect negative correlation, meaning that as one variable goes up, the other goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea08627",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_triangle = np.tril(df.corr())\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, square=True, fmt='0.3f', \n",
    "            annot_kws={'size':10}, cmap=\"Spectral\", mask=lower_triangle)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7825013",
   "metadata": {},
   "source": [
    "I see that the above heatmap shows the correlation matrix data wherein there are positive as well as negative correlations between the target label and other feture columns. A zero correlation indicates that there is no relationship between the variables. Looking at the above representation I see that quality column is positively correlated with alcohol and it is negatively correlated with the volatile acidity. The quality column is least correlated with residual sugar showing a coefficient value of 0.014 that close to 0. Similarly we can bifurcate all the other positively and negatively correlated feature columns with respect to the target label.\n",
    "\n",
    "Also there are some highly positive and negative correlated feature columns that can pose the concern for multicollinearity. If the correlation coefficient, assuming it to be the variable 'r', is exactly +1 or -1, then it is called perfect multicollinearity. But even if this 'r' is close to -1 or +1 then one of the features should be removed from the model if at all possible.\n",
    "\n",
    "Right now I see columns fixed acidity and citirc acid are positively correlated with a value of 0.672 which is close to 1. Similary, columns fixed acidity and density are positively correlated with a value of 0.668 again being close to 1. The other 2 column that's positively correlated are free sulfur dioxide and total sulfur dioxide with a value of 0.668 which is close to the value 1. The only negatively correlated columns that pop up are fixed acitidy and pH with a value -0.683 being close to the value -1.\n",
    "\n",
    "We may need to deal with multicollinearity later if required to improve the accuracy of our machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94f42b",
   "metadata": {},
   "source": [
    "## Dropping a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a99546c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfree sulfur dioxide\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.drop('free sulfur dioxide', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70596e4b",
   "metadata": {},
   "source": [
    "1599 rows × 11 columns\n",
    "\n",
    "I feel that free sulfur dioxide and total sulfur dioxide are both indicating towards the same feature of sulfur dioxide therefore I am dropping the free option and keeping just the total option in our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9bbd9",
   "metadata": {},
   "source": [
    "## Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e2c54",
   "metadata": {},
   "source": [
    "(1599, 11)\n",
    "Confirming the number of columns and rows before removing the outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0798ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Z score method\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m z\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mabs(zscore(df))\n\u001b[0;32m      4\u001b[0m threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mwhere(z\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Z score method\n",
    "\n",
    "z=np.abs(zscore(df))\n",
    "threshold=3\n",
    "np.where(z>3)\n",
    "\n",
    "df=df[(z<3).all(axis=1)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aaeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e452f7",
   "metadata": {},
   "source": [
    "(1464, 11)\n",
    "Checking the number of rows present in the dataset after applying the outlier removal technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of Data Loss\n",
    "\n",
    "data_loss=(1599-1464)/1599*100 \n",
    "# 1599 (number of rows in the original dataframe) and 1464 (number of rows after outlier removal)\n",
    "data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e77a49",
   "metadata": {},
   "source": [
    "8.442776735459661\n",
    "After removing the outliers we are checking the data loss percentage by comparing the rows in our original data set and the new data set post removal of the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8c1e8",
   "metadata": {},
   "source": [
    "## Splitting the dataset into 2 variables namely 'X' and 'Y' for feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd56ccfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = df.drop('quality', axis=1)\n",
    "Y = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3b9d2",
   "metadata": {},
   "source": [
    "## Taking care of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aae644",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12258443",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# adding samples to make all the categorical quality values same\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m oversample \u001b[38;5;241m=\u001b[39m \u001b[43mSMOTE\u001b[49m()\n\u001b[0;32m      4\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m oversample\u001b[38;5;241m.\u001b[39mfit_resample(X, Y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "# adding samples to make all the categorical quality values same\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b762169",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mY\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0e7715",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mY\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "Y # Displaying just the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b4b10",
   "metadata": {},
   "source": [
    "## Label Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d8afb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mY\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m y_value:\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_value\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 1 is for good quality and 0 for bad (not good) quality\u001b[39;00m\n\u001b[0;32m      2\u001b[0m Y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "Y = Y.apply(lambda y_value:1 if y_value>=7 else 0) # 1 is for good quality and 0 for bad (not good) quality\n",
    "Y # Displaying the label after applying label binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0759020",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X # Displaying all the features except the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bdb93",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27110a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m()\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scaler\u001b[38;5;241m.\u001b[39mfit_transform(X), columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      3\u001b[0m X\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X # Displaying all the features after applying scaling technique to avoid bias output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f36f4",
   "metadata": {},
   "source": [
    "## Creating the training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca189999",
   "metadata": {},
   "source": [
    "I am taking 20 percent of the complete dataset for training purpose and the remaing 80 percent with be used to train the machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b1475",
   "metadata": {},
   "source": [
    "## Machine Learning Model for Classification and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Model Function\n",
    "\n",
    "def classify(model, X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting Y_test\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy Score\n",
    "    acc_score = (accuracy_score(Y_test, pred))*100\n",
    "    print(\"Accuracy Score:\", acc_score)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(Y_test, pred)\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "    \n",
    "    # Cross Validation Score\n",
    "    cv_score = (cross_val_score(model, X, Y, cv=5).mean())*100\n",
    "    print(\"Cross Validation Score:\", cv_score)\n",
    "    \n",
    "    # Result of accuracy minus cv scores\n",
    "    result = acc_score - cv_score\n",
    "    print(\"\\nAccuracy Score - Cross Validation Score is\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d752fc",
   "metadata": {},
   "source": [
    "I have defined a class that will perform the train-test split, training of machine learning model, predicting the label value, getting the accuracy score, generating the classification report, getting the cross validation score and the result of difference between the accuracy score and cross validation score for any machine learning model that calls for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b927551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model=LogisticRegression()\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78596e",
   "metadata": {},
   "source": [
    "Accuracy Score: 89.74358974358975\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.91      0.92       391\n",
    "           1       0.85      0.88      0.86       233\n",
    "\n",
    "    accuracy                           0.90       624\n",
    "   macro avg       0.89      0.89      0.89       624\n",
    "weighted avg       0.90      0.90      0.90       624\n",
    "\n",
    "Cross Validation Score: 88.20512820512822\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 1.538461538461533\n",
    "Created the Logistic Regression Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed274e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "model=SVC(C=1.0, kernel='rbf', gamma='auto', random_state=42)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60f7f3",
   "metadata": {},
   "source": [
    "Accuracy Score: 91.50641025641025\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.93      0.93       391\n",
    "           1       0.88      0.90      0.89       233\n",
    "\n",
    "    accuracy                           0.92       624\n",
    "   macro avg       0.91      0.91      0.91       624\n",
    "weighted avg       0.92      0.92      0.92       624\n",
    "\n",
    "Cross Validation Score: 90.06410256410255\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 1.4423076923076934\n",
    "Created the Support Vector Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d092c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "model=DecisionTreeClassifier(random_state=21, max_depth=15)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67f69",
   "metadata": {},
   "source": [
    "Accuracy Score: 93.26923076923077\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.93      0.95       391\n",
    "           1       0.89      0.93      0.91       233\n",
    "\n",
    "    accuracy                           0.93       624\n",
    "   macro avg       0.93      0.93      0.93       624\n",
    "weighted avg       0.93      0.93      0.93       624\n",
    "\n",
    "Cross Validation Score: 89.32692307692308\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 3.9423076923076934\n",
    "Created the Decision Tree Classifier Model and checked for it's evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420603be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "model=RandomForestClassifier(max_depth=15, random_state=111)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d466ff",
   "metadata": {},
   "source": [
    "Accuracy Score: 95.03205128205127\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.95      0.96       391\n",
    "           1       0.92      0.95      0.93       233\n",
    "\n",
    "    accuracy                           0.95       624\n",
    "   macro avg       0.94      0.95      0.95       624\n",
    "weighted avg       0.95      0.95      0.95       624\n",
    "\n",
    "Cross Validation Score: 92.27564102564102\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 2.7564102564102484\n",
    "Created the Random Forest Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607216ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Neighbors Classifier\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=15)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02ae5c",
   "metadata": {},
   "source": [
    "Accuracy Score: 91.34615384615384\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.90      0.93       391\n",
    "           1       0.85      0.94      0.89       233\n",
    "\n",
    "    accuracy                           0.91       624\n",
    "   macro avg       0.90      0.92      0.91       624\n",
    "weighted avg       0.92      0.91      0.91       624\n",
    "\n",
    "Cross Validation Score: 88.7179487179487\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 2.6282051282051384\n",
    "Created the K Neighbors Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf22680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Classifier\n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc88d28",
   "metadata": {},
   "source": [
    "Accuracy Score: 95.51282051282051\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.96      0.96       391\n",
    "           1       0.94      0.94      0.94       233\n",
    "\n",
    "    accuracy                           0.96       624\n",
    "   macro avg       0.95      0.95      0.95       624\n",
    "weighted avg       0.96      0.96      0.96       624\n",
    "\n",
    "Cross Validation Score: 92.98076923076923\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 2.5320512820512846\n",
    "Created the Extra Trees Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa390916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Classifier\n",
    "\n",
    "model=xgb.XGBClassifier(verbosity=0)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dcec3e",
   "metadata": {},
   "source": [
    "Accuracy Score: 95.51282051282051\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.95      0.96       391\n",
    "           1       0.92      0.96      0.94       233\n",
    "\n",
    "    accuracy                           0.96       624\n",
    "   macro avg       0.95      0.96      0.95       624\n",
    "weighted avg       0.96      0.96      0.96       624\n",
    "\n",
    "Cross Validation Score: 92.43589743589745\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 3.076923076923066\n",
    "Created the XGB Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM Classifier\n",
    "\n",
    "model=lgb.LGBMClassifier()\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a902e6",
   "metadata": {},
   "source": [
    "Accuracy Score: 95.1923076923077\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.95      0.96       391\n",
    "           1       0.92      0.95      0.94       233\n",
    "\n",
    "    accuracy                           0.95       624\n",
    "   macro avg       0.95      0.95      0.95       624\n",
    "weighted avg       0.95      0.95      0.95       624\n",
    "\n",
    "Cross Validation Score: 92.37179487179488\n",
    "\n",
    "Accuracy Score - Cross Validation Score is 2.8205128205128176\n",
    "Created the LGBM Classifier Model and checked for it's evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821d38c",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning on the best ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa25bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Support Vector Classifier\n",
    "\n",
    "svc_param = {'kernel' : ['poly', 'sigmoid', 'rbf'],\n",
    "             'gamma' : ['scale', 'auto'],\n",
    "             'shrinking' : [True, False],\n",
    "             'random_state' : [21,42,104],\n",
    "             'probability' : [True, False],\n",
    "             'decision_function_shape' : ['ovo', 'ovr'],\n",
    "             'verbose' : [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33139b",
   "metadata": {},
   "source": [
    "After comparing all the classification models I have selected Support Vector Classifier as my best model and have listed down it's parameters above referring the sklearn webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780000db",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV = GridSearchCV(SVC(), svc_param, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08c468",
   "metadata": {},
   "source": [
    "I am using the Grid Search CV method for hyper parameter tuning my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4273e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60eabf4",
   "metadata": {},
   "source": [
    "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f425298",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(cv=5, estimator=SVC(),\n",
    "             param_grid={'decision_function_shape': ['ovo', 'ovr'],\n",
    "                         'gamma': ['scale', 'auto'],\n",
    "                         'kernel': ['poly', 'sigmoid', 'rbf'],\n",
    "                         'probability': [True, False],\n",
    "                         'random_state': [21, 42, 104],\n",
    "                         'shrinking': [True, False], 'verbose': [True, False]})\n",
    "I have trained the Grid Search CV with the list of parameters I feel it should check for best possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9db970",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'decision_function_shape': 'ovo',\n",
    " 'gamma': 'scale',\n",
    " 'kernel': 'rbf',\n",
    " 'probability': True,\n",
    " 'random_state': 21,\n",
    " 'shrinking': True,\n",
    " 'verbose': True}\n",
    "Here the Grid Search CV has provided me with the best parameters list out of all the combinations it used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model = SVC(decision_function_shape='ovo', gamma='scale', kernel='rbf', probability=True, random_state=21,\n",
    "                 shrinking=True, verbose=True)\n",
    "Classifier = Final_Model.fit(X_train, Y_train)\n",
    "fmod_pred = Final_Model.predict(X_test)\n",
    "fmod_acc = (accuracy_score(Y_test, fmod_pred))*100\n",
    "print(\"Accuracy score for the Best Model is:\", fmod_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c473a",
   "metadata": {},
   "source": [
    "[LibSVM]Accuracy score for the Best Model is: 91.50641025641025\n",
    "I have successfully incorporated the Hyper Parameter Tuning on my Final Model and received the accuracy score for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f4187",
   "metadata": {},
   "source": [
    "## AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa506da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.plot_roc_curve(Final_Model, X_test, Y_test)\n",
    "disp.figure_.suptitle(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b7883",
   "metadata": {},
   "source": [
    "I have generated the ROC Curve for my final model and it shows the AUC score for my final model to be of 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab0e71",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96499a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = df.columns\n",
    "metrics.plot_confusion_matrix(Classifier, X_test, Y_test, cmap='mako')\n",
    "plt.title('\\t Confusion Matrix for Decision Tree Classifier \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9127fc",
   "metadata": {},
   "source": [
    "With the help of above confusion matrix I am able to understand the number of times I got the correct outputs and the number of times my model missed to provide the correct prediction (depicting in the black boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeafbb5d",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36788db",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"FinalModel_3.pkl\"\n",
    "joblib.dump(Final_Model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "['FinalModel_3.pkl']\n",
    "Finally I am saving my best classification model using the joblib library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
